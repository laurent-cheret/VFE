{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TKEfNGBAJfk"
      },
      "source": [
        "# Encoding High-Level Features: An Approach to Robust Transfer Learning.\n",
        "## This code shows variational autoencoders being used to reduce dimensionality of feaure maps and provide the encoded representation to an image classifier. This work is an attempt to improve the robustness of the classic image classification architecture by performing a simple change to the overall system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXuwBRbYAGmQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGJ-3HbVJQYU"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(image, label):\n",
        "\n",
        "  image2 = tf.keras.applications.densenet.preprocess_input(image)\n",
        "  return image2, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxLo_RxBJeFj"
      },
      "outputs": [],
      "source": [
        "#### CREATE BASE MODEL FOR FEATURE EXTRACTION #####\n",
        "\n",
        "def base_model():\n",
        "\n",
        "  base_model = tf.keras.applications.DenseNet121(include_top= False, weights = 'imagenet', input_shape = (224,224,3))\n",
        "  print(len(base_model.layers))\n",
        "  for layer in base_model.layers[:200]:\n",
        "    layer.trainable = False\n",
        "  for layer in base_model.layers[200:]:\n",
        "    layer.trainable = True\n",
        "  base_model.summary()\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(tf.keras.layers.Lambda(lambda img: tf.image.resize(img, (224,224))))\n",
        "  model.add(base_model)\n",
        "  model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m8FlfNpJJuu0"
      },
      "outputs": [],
      "source": [
        "base_model = base_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XnEB0mcGJ3XK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3676da7-7688-4c69-c330-1cab03e140ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 2s 0us/step\n",
            "170508288/170498071 [==============================] - 2s 0us/step\n"
          ]
        }
      ],
      "source": [
        "#### LOADING CIFAR10 DATASET\n",
        "\n",
        "def load_data():\n",
        "  (x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "  x_train = x_train.astype('float32')\n",
        "  x_test = x_test.astype('float32')\n",
        "\n",
        "  # Convert class vectors to binary class matrices.\n",
        "  y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "  y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "  train_ds = tf.data.Dataset.from_tensor_slices((x_train[:],y_train[:]))\n",
        "  test_ds = tf.data.Dataset.from_tensor_slices((x_test[:2000], y_test[:2000]))\n",
        "  train_ds = train_ds.map(lambda x,y: (preprocess_data(x,y)))\n",
        "  test_ds = test_ds.map(lambda x,y: (preprocess_data(x,y)))\n",
        "  batch_size = 100\n",
        "\n",
        "  train_ds = train_ds.cache().batch(batch_size).prefetch(buffer_size=1000)\n",
        "  test_ds = test_ds.cache().batch(batch_size).prefetch(buffer_size=1000)\n",
        "  return train_ds, test_ds\n",
        "\n",
        "train_ds, test_ds = load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC3wWiSXKQwD"
      },
      "source": [
        "## Let's start by training the classical image classifier composed of a feature extractor (DCNN) and a classifier (neural net).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbcviGs5Kjdy"
      },
      "outputs": [],
      "source": [
        "#### LOADING AND TRAINING THE COMPARATIVE MODEL\n",
        "compare_model = tf.keras.Sequential()\n",
        "compare_model.add(base_model)\n",
        "compare_model.add(tf.keras.layers.Dropout(0.3))\n",
        "compare_model.add(tf.keras.layers.Dense(10, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "icO6wVqoKrQT"
      },
      "outputs": [],
      "source": [
        "compare_model.compile(loss = 'categorical_crossentropy', metrics = ['accuracy'], optimizer = 'adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrbYmKKmK7EN"
      },
      "outputs": [],
      "source": [
        "training1 = compare_model.fit(train_ds, epochs = 30, verbose=1, validation_data = test_ds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNiS1vTDLKAc"
      },
      "source": [
        "## We then freeze the DCNN to preserve the feature space and generate the feature maps for the dataset at hand."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8lQcPBJLWrN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d5ce03e-3bb3-45f4-93eb-90be1d5ad1cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 134s 263ms/step\n"
          ]
        }
      ],
      "source": [
        "base_model.trainable = False\n",
        "feat_maps_cifar = base_model.predict(train_ds, verbose = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvXxm3y_Mh2l"
      },
      "source": [
        "## Variational Feature Encoder\n",
        "This section uses a variational autoencoder composed only of dense layers to perform dimensionality reduction of feature maps. It is trained to reconstruct feature maps from CIFAR10 dataset. Once it is trained we use the encoded representation in the latent space to feed a new classifier. This new system is now composed of the frozen DCNN, the encoder part of the variational autoencoder (VFE) and the classifier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6pPJ0zLNuq7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f833a38-d0b9-4068-fc59-ad6edc4e15b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_11 (InputLayer)          [(None, 1024)]       0           []                               \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 256)          262400      ['input_11[0][0]']               \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 256)         1024        ['dense_12[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " z_mean (Dense)                 (None, 256)          65792       ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " z_log_var (Dense)              (None, 256)          65792       ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " sampling_3 (Sampling)          (None, 256)          0           ['z_mean[0][0]',                 \n",
            "                                                                  'z_log_var[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 395,008\n",
            "Trainable params: 394,496\n",
            "Non-trainable params: 512\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 256)]             0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1024)              525312    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 658,944\n",
            "Trainable params: 657,920\n",
            "Non-trainable params: 1,024\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#### CREATING THE VARIATIONAL AUTOENCODER\n",
        "\n",
        "## THE SAMPLING BLOCK TAKES THE OUTPUT OF THE MEAN AND VARIANCE BLOCKS.\n",
        "## IT THEN PROVIDES A DISTRIBUTION TO THE DECODER WHICH HAS THE TASK OF RECONSTRUCTING THE FEATURE MAPS.\n",
        "\n",
        "\n",
        "class Sampling(tf.keras.layers.Layer):\n",
        "  \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n",
        "\n",
        "  def call(self, inputs):\n",
        "      z_mean, z_log_var = inputs\n",
        "      batch = tf.shape(z_mean)[0]\n",
        "      dim = tf.shape(z_mean)[1]\n",
        "      epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n",
        "      return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "## DIMENSIONALITY OF THE LATENT SPACE\n",
        "latent_dim = 256\n",
        "\n",
        "encoder_inputs = tf.keras.Input(shape=(1024,))\n",
        "x = tf.keras.layers.Dense(256, activation = 'relu')(encoder_inputs)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "z_mean = tf.keras.layers.Dense(latent_dim, name=\"z_mean\")(x)\n",
        "z_log_var = tf.keras.layers.Dense(latent_dim, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "encoder = tf.keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "latent_inputs = tf.keras.Input(shape=(latent_dim,))\n",
        "x = tf.keras.layers.Dense(512, activation='relu')(latent_inputs)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "decoder_outputs = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
        "decoder = tf.keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "## DEFINING THE LOSSES TO BE USED IN THE TRAINING PROCESS\n",
        "## MEAN SQUARRED ERROR\n",
        "def mse_loss(y_true, y_pred):\n",
        "\n",
        "    r_loss = tf.reduce_mean(tf.square(y_true - y_pred))\n",
        "    ## MULTIPLICATIVE FACTOR ON THE TOTAL LOSS (1000)\n",
        "    return 1000*r_loss\n",
        "\n",
        "##Kullblack-Leibler Divergence Factor\n",
        "def kl_loss(mean, log_var):\n",
        "\n",
        "    kl_loss =  -0.5 * (1 + log_var - tf.square(mean) - tf.exp(log_var))\n",
        "    ## BETA = 1\n",
        "    return 1*kl_loss\n",
        "\n",
        "## TOTAL LOSS\n",
        "def vae_loss(y_true, y_pred, mean, var):\n",
        "\n",
        "    r_loss = mse_loss(y_true, y_pred)\n",
        "    kl_loss_ = kl_loss(mean, var)\n",
        "    return  r_loss + kl_loss_\n",
        "\n",
        "\n",
        "\n",
        "## DEFINING THE TRAINING PROCESS AND THE OBJECTIVE FUNCTION TO CALCULATE THE LOSS\n",
        "\n",
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.total_loss_tracker = tf.keras.metrics.Mean(name=\"total_loss\")\n",
        "        self.reconstruction_loss_tracker = tf.keras.metrics.Mean(\n",
        "            name=\"reconstruction_loss\"\n",
        "        )\n",
        "        self.kl_loss_tracker = tf.keras.metrics.Mean(name=\"kl_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [\n",
        "            self.total_loss_tracker,\n",
        "            self.reconstruction_loss_tracker,\n",
        "            self.kl_loss_tracker,\n",
        "        ]\n",
        "\n",
        "    def train_step(self, data):\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "\n",
        "            z_mean, z_log_var, z = self.encoder(data)\n",
        "            reconstruction = self.decoder(z)\n",
        "            reconstruction_loss = mse_loss(data, reconstruction)\n",
        "            kl_loss_ = kl_loss(z_mean, z_log_var)\n",
        "            total_loss = vae_loss(data, reconstruction, z_mean, z_log_var)\n",
        "\n",
        "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
        "        self.total_loss_tracker.update_state(total_loss)\n",
        "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
        "        self.kl_loss_tracker.update_state(kl_loss_)\n",
        "\n",
        "        return {\n",
        "            \"loss\": self.total_loss_tracker.result(),\n",
        "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
        "            \"kl_loss\": self.kl_loss_tracker.result(),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTb-5oajPqH0"
      },
      "outputs": [],
      "source": [
        "vae = VAE(encoder, decoder)\n",
        "vae.compile(optimizer=tf.keras.optimizers.Adam(), metrics = ['accuracy'])\n",
        "training_vae_cifar = vae.fit(feat_maps_cifar, epochs=2000, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjOmVGSNPxYT"
      },
      "source": [
        "## Once the training of the VFE is done we freeze it and connect to the feature extractor to train a new classifier that will take encoded representations of feature maps and map it to given classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6kKzT4iPwq8"
      },
      "outputs": [],
      "source": [
        "vae.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3yyC7sFhQmvM"
      },
      "outputs": [],
      "source": [
        "def classifier():\n",
        "\n",
        "  inputs = tf.keras.Input(shape = (256,))\n",
        "  x = tf.keras.layers.Dropout(0.3)(inputs)\n",
        "  outputs = tf.keras.layers.Dense(10, activation = 'softmax')(x)\n",
        "  classifier = tf.keras.Model(inputs, outputs, name = 'classifier')\n",
        "  return classifier\n",
        "\n",
        "classifier = classifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lh10n7k1Qv9D"
      },
      "outputs": [],
      "source": [
        "## CREATING THE IMAGE CLASSIFIER WITH VFE\n",
        "\n",
        "model1 = tf.keras.Model(base_model.input, vae.encoder(base_model.output))\n",
        "model_global = tf.keras.Model(model1.input, classifier(model1.output[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAsxwzChQ_TT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3109fefc-23f0-4c05-8b74-dd7f7c5541eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lambda_input (InputLayer)   [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1024)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 256),             395008    \n",
            "                              (None, 256),                       \n",
            "                              (None, 256)]                       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,432,512\n",
            "Trainable params: 0\n",
            "Non-trainable params: 7,432,512\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYNcFaNuRBSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc4d23f-f9de-4d21-c07f-08168cad896b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lambda_input (InputLayer)   [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " lambda (Lambda)             (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " densenet121 (Functional)    (None, 7, 7, 1024)        7037504   \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1024)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " encoder (Functional)        [(None, 256),             395008    \n",
            "                              (None, 256),                       \n",
            "                              (None, 256)]                       \n",
            "                                                                 \n",
            " classifier (Functional)     (None, 10)                2570      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 7,435,082\n",
            "Trainable params: 2,570\n",
            "Non-trainable params: 7,432,512\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model_global.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfeJM6yBRCaS"
      },
      "outputs": [],
      "source": [
        "model_global.compile(optimizer= 'Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "training = model_global.fit(train_ds, epochs = 50, verbose = 1, validation_data=test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9uTr_bP8__MU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Feature_encoder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}